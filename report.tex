\documentclass[10pt]{article}
\title{\textbf{Machine Learning Project Report }}
\author{Michele Orr\`u}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{unitsdef}

\begin{document}
\maketitle

\begin{abstract}
The purpose of this project is to implement a two-step analysis and classification of magnetoencephalography(MEG) data. 
\end{abstract}



\section{Introduction}
Given a user shifting his attention to the left or to the right and monitoring the spatial and temporal status of the MEG\cite{Biomag2010} signal, the goal is to build a classifier capable of brain-decode \textit{a-posteriori} towards which direction the user was actually shifting his attention.



\section{Dataset}
in the following we describe how the input data was given, and how it is structured. 

Input data was taken from the Biomag 2010 contest, first analyzed in 
\cite{Biomag2010} and then in \cite{Braindecoding}: it consists in
 magnetoencephalography(MEG) data collected from 15 subjects who were engaged in
a task where they covertly had to visually attend left, right, up, or down during a
period of 2500\milli\second. 
MEG data was then transformated using spectral energy distribution COSA VUOL DIRE
and then compressed in two numpy pickled binary files (\texttt{\.npz}), 
namely \texttt{freq\_left\_gradient.npy.npz} and 
\texttt{freq\_left\_gradient.npy.npz}.

The phenomenom has been described as a vector
$\{(trial_i, direction_i)\}_{i= 1, 2, \dots, trials}$, where:

$$
trial_i  = t
 \begin{bmatrix}
   freq_{0, 0} & freq_{0, 1} & \cdots & freq_{0, t}  \\
   freq_{1, 0} & freq_{1, 1} & \cdots & freq_{1, t}  \\
   \vdots      & \vdots      & \ddots & \vdots       \\
   freq_{n, 0} & freq_{n, 1} & \cdots & freq_{n, t} 
 \end{bmatrix}
\hspace{30pt}
 direction_i = \left\{
 \begin{array}{l l}
   -1 & \text{if left}\\
   +1 & \text{if right}\\
 \end{array}\right .
$$

More precisely, $trial_i \in \mathbb{R} ^{n+t}$ represents over each row one of the $n=274$ channels sonded, and over each column the mean for each of the $t=6$ different band ranges, respectively:
$\{2..4, 4..8, 8..13, 13..20, 20..35, 35..46\}$ $\hertz$ .

Globally, we have $255$ trials ($127$ left, $128$ right) taken over one single ($1$) subject.  


\section{Problem Formulation}
The problem of classifying the shift of attention to
the left ($-1$) or to the right ($-1$) has been
approached by stacking\cite{Wolpert92} two different
models. The first one consists in a vector of
learning functions, one for each channel, expected to
predict the \emph{local} direction; the second one
instead, is expected to predict the \emph{global}
output, given the local information.

Reasons for this choices are to be found in a reduction of the dimensionality of the feature space, and into a better balance between the number of instances and the number of features.
Furthermore, by stacking, we should presumibly
achieve a most accurate learning model extending the crossvalidation concept, as described in (Wolpert, 1992, Introduction)\cite{Wolpert92}, and in a reserach interest concerning localized informations of the brain.


\subsection{Formalization} 

\paragraph{First Step} is a set of function 
$ \{f_0, f_1, \dots, f_n \}$ 
taking as input the frequency bands, for a specific trial over all trials and expressing the best direction ($left=-1$, $right=+1$), in terms of confidence within the interval $[-1, +1]$. Hence, we can define them as:
$$
\begin{array}{lr}
f_k: (\begin{array}{l l l} freq_{k, 0}, & \cdots, & freq_{k, t} \end{array})^{trials} \to [-1, 1]^{trials},
&
k \in \{0, \dots, n\}
\end{array}
$$ 

\paragraph{Second Step} we are looking for a funciton expressing the global output as a boolean value, given the localized information about each channel previously discovered and then aggregated:
$$
g: [-1, +1]^n \to \{-1, +1\}
$$


\subsection{Learning Model}

\paragraph{First Step} each of the ${f_k}$ function has been trained using a \textbf{non-linear SVM classifier}.

Non-linear SVM classifiers are modeled 

\paragraph{Second Step} $g$ instead, was trained using a simple \textbf{norm-one classifier}
Norm-one classifiers simple attempt to define the linear hyperplane 
$w^T + w_0$ using $||w||_1$


\subsection{Evaluations for Stacking}
describe here the process of evaluation for stacked classifers, sketching the procedure to train and test the proposed stacked architecture.


\subsection{Training}
ho to train data?


\subsection{Validation}
use 10-fold crossvalidation.



\section{Implementation}
The implementation is done in pure 
\href{https://python.org/}{python}
, using the
\href{http://scikit-learn.org/stable/}{scikit-learn}
module. Documentatios has been automatically generated by
\href{http://sphinx-doc.org/}{Sphinx}, the most widely used documentation generator in pyton.

Source code is available on 
\href{https://github.com/mmaker/braindecoding}{GitHub}.

\subsection{Code Structure}
bulabulabula
\subsection{Crucial Parts}
write here some algorithmic using \href{https://en.wikibooks.org/wiki/LaTeX/Algorithms_and_Pseudocode}{pseudocodice per pseudoscienziati}


\section{Conclusions}
Before the descrived learning model, others were tested.
[\dots]
As a closing conclusion, we highlight the main foundings of the project.
[\dots]




\begin{thebibliography}{9}
\bibitem{Biomag2010}
Marcel van Gerven, Ole Jensen,
\emph{Attention modulations of posterior alpha as a control signal for two-dimensional brain-computer interfaces},
Journal of Neuroscience Methods, 2009

\bibitem{Wolpert92}
David H. Wolpert,
\emph{Stacked Generalization},
Neural Networks, 1992

\bibitem{Braindecoding}
E. Olivetti, A. Mognon, S. Greiner and P. Avesani, 
\emph{Brain Decoding: Biases in Error Estimation}, 
Brain Decoding Workshop, 2010

\end{thebibliography}

\end{document}


