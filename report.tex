\documentclass[10pt]{article}
\title{\textbf{Machine Learning Project Report }}
\author{Michele Orr\`u}
\usepackage{subfig}
\usepackage{float}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{unitsdef}
\usepackage{hyperref}
\usepackage{graphicx}
\begin{document}
\newcommand{\code}[1]{\texttt{#1}}
\maketitle
\begin{abstract}
The purpose of this project is to implement a two-step analysis and classification of magnetoencephalography(MEG) data. 
\end{abstract}


\section{Introduction}
Given a user shifting his attention to the left or to the right and monitoring the spatial and temporal status of the MEG\cite{Biomag2010} signal, the goal is to build a classifier capable of brain-decode \textit{a-posteriori} towards which direction the user was actually shifting his attention.



\section{Dataset}
\label{dataset}
In the following we describe how the input data was given, and how it is structured. 

\noindent
Input data was taken from the Biomag 2010 contest, first analyzed in 
\cite{Biomag2010} and then in \cite{Braindecoding}: it consists in
 magnetoencephalography(MEG) data collected from 15 subjects who were engaged in
a task where they covertly had to visually attend left, right, up, or down during a
period of 2500\milli\second. 
Then, MEG data has been filtered for left, right directions, transformated using spectral energy distribution and compressed in two numpy pickled binary files
 (\code{.npz}), namely \code{freq\_left\_gradient.npy.npz}
 and \code{freq\_left\_gradient.npy.npz}.

More formally, those files contains the dump of a dict-like area of memory, with keys:
\begin{verbatim}
>>> np.load('freq_left_gradient.npy.npz')
<numpy.lib.npyio.NpzFile object at 0x251cad0>
>>> print _.keys()
['sample_freq', 'lf_freq', 'time', 'label', 'fsample']
\end{verbatim}

\code{time}, \code{label}, and \code{sample\_freq} are vectors labelling respectively when, where, and on which frequency data was sampled.
\code{lf\_freq} contains the real inputs (N.B., right samples contains key \code{rg\_freq}), espressed as a matrix $(127, 274, 376)$ $trials \times channel \times frequency$.

\paragraph{Preprocessing} A preprocessing directive has been implemented, in order to reduce dimensionality of the input space, and have quicker access to the features. It simply extracts data from the previously discussed files, and outputs a \code{dataset.npz} dict-like, having keys:
\begin{verbatim}
>>> np.load('dataset.npz')
<numpy.lib.npyio.NpzFile object at 0x25e31d0>
>>> _.keys()
['label', 'dataset']
\end{verbatim}
where \code{label} contains labelling information for each channel, and \code{dataset} is a vector $\{(trial_i, direction_i)\}_{i= 1, 2, \dots, trials}$, such that:

$$
trial_i  = 
 \begin{bmatrix}
   freq_{0, 0} & freq_{0, 1} & \cdots & freq_{0, b}  \\
   freq_{1, 0} & freq_{1, 1} & \cdots & freq_{1, b}  \\
   \vdots      & \vdots      & \ddots & \vdots       \\
   freq_{n, 0} & freq_{n, 1} & \cdots & freq_{n, b} 
 \end{bmatrix}
\hspace{30pt}
 direction_i = \left\{
 \begin{array}{l l}
   -1 & \text{if left}\\
   +1 & \text{if right}\\
 \end{array}\right .
$$
More precisely, $trial_i \in \mathbb{R} ^{n+b}$ represents over each row one of the $n=274$ channels sonded, and over each column the mean for each of the $b=7$ different band ranges, respectively:
$$
\{0.0 \dots 24.7,\ 24.7 \dots 49.5,\ 49.5 \dots 74.2,\ 74.2 \dots 98.9,\ 98.9 \dots 123.7,\ 123.7 \dots 148.4\} \ \hertz
$$
Globally, we have $255$ trials ($127$ left, $128$ right).


\section{Problem Formulation}
The problem of classifying the shift of attention to
the left ($-1$) or to the right ($-1$) has been
approached by stacking\cite{Wolpert92} two different
models. The first one consists in a vector of
learning functions, one for each channel, expected to
predict the \emph{local} direction; the second one
instead, is expected to predict the \emph{global}
output, given the local information.

Reasons for this choices are to be found mostly in a reserach interest concerning localized informations of the brain.
Furthermore, by stacking, we should presumibly
reduce the dimensionality of the feature space, and reach a better balance between the number of instances and the number of features.

\subsection{Formalization} 

\paragraph{First Step} As stated above, first step consists in a vector of functions
$ \{f_0,\ f_1,\ \dots,\ f_n \}$ 
taking as input the frequency bands over a specific channel and expressing the best direction ($left$, $right$), in terms numeric values $(-1, +1)$. Hence, we can define them as:
$$
\begin{array}{lr}
f_k: (\begin{array}{l l l} freq_{k, 0}, & \cdots, & freq_{k, t} \end{array}) \to \{-1, 1\},
&
k \in \{0, \dots, n\}
\end{array}
$$ 

\paragraph{Second Step} we are looking for a funciton expressing the global output as a boolean value, given the localized information about each channel previously discovered and then aggregated:
$$
g: \{-1, +1\}^n \to \{-1, +1\}
$$


\subsection{Learning Model}
\label{learning_model}

\paragraph{First Step} each of the ${f_k}$ function has been trained using a \textbf{non-linear SVM classifier}, with \emph{gaussian} and \emph{polynomial} kernels. 

\paragraph{Second Step} $g$ instead, was trained using a simple \textbf{norm-one classifier}
Norm-one classifiers constructs the separating hyperplane 
$g(\boldsymbol{x}) = w^T\boldsymbol{x} + w_0$ using $||w||_1$ for support vector selection.


\subsection{Evaluations for Stacking}

The stacked architecture adds extra complexity to the model for feature selection. In fact, constraints for features selection are: 
\begin{itemize}
\item $f_k$'s training set \emph{must} not have examples in common with the validation set;
\item $g$'s training set \emph{must} not have examples in common with the validation set;
\item $f_k$'s training set \emph{should} have null intersection with the $g$ training set.
\end{itemize}

Hence, an \emph{outer} 10-fold crossvalidation has been used for splitting the data in training and validation set; and another one, \emph{inner}, using the training data of the outer set for training both the $f_k$ and $g$. 

\subsection{Training}

The first step is to train each channel-specific learner, using the selected features for training, filtered for the specic channel. 
\begin{verbatim}
fst[channel].fit(input[:, channel], output)
\end{verbatim}

\noindent
Then, the second classifier is trained using the selected features for the second training step, applied to the first layer of learners.
\begin{verbatim}
input = np.array([fst[channel].predict(input[:, channel])
                   for channel in xrange(channels)]).T
snd.fit(input, output)

\end{verbatim}


\subsection{Validation}
Each round of cross-validation involves a combination of $f_k$s and $g$ which is eventually saved to disk if its accuracy is over $75\%$. 
Globally, only the tuple of learners having best accuracy is considered.
Besides all this, the best learnerns achieved by constraints tuning has been selected by examining the output logs \code{output.log}, and \code{output.log.1}.

\section{Implementation}
The implementation is done in pure 
\href{https://python.org/}{python}
, version $>=2.6$, using the \href{http://scikit-learn.org/stable/}{scikit-learn}
module. Documentation available via the \code{help()} fucntion. 
Source code hosted on \href{https://github.com/mmaker/braindecoding}{GitHub}.

\subsection{Code Structure}
File \code{braindecoding.py} handles preprocessing, learning and validation. It is composed of four main functions, each one bindend to a specific command: 
\begin{itemize}
\item \code{preprocess()}, binded to \code{-p}, performs the preprocessing discussed in section \nameref{dataset};
\item \code{learn(parameters=None)}, binded to \code{-l}, performs the learning as described in section \nameref{learning_model};
\item \code{tune(processes=None)}, binded to \code{-t}, starts up a pool of processes, each one computing a \code{learn()} function. Used for validation.
\item \code{plot(filter, outputfile)}, binded to \code{-d}, visualizes the performance for the kernel specified (\code{filter}) on the log file \code{outputfile}.
\end{itemize}

\section{Conclusions}
Performance has been evaluated only computing the accuracy of the outer classifier. Even thouth succint, is a valuable method for having an idea of the flexibility of the learner.

Examining files \code{output.log*} shown that \emph{polynomial} kernels had a higher density of learners above the $75\%$ of accuracy.

\begin{figure}[H]
\includegraphics[width=.4\textwidth]{output-rbf-1.png}
\hfill
\includegraphics[width=.6\textwidth]{output-poly-1.png}
\hfill
\caption{Performance graph on \code{output.log.1}}
\end{figure}

\paragraph{Further improvements} A better performance could have been achieved defining the codomain of each $f_k$ as an interval $[-1, +1]$, using \emph{support vector regression}'s implementation \code{sklearn.svm.SVR}, which has not been done for a pure matter of execution time, not for implementation difficulties.
Another side on which the learner is currently inefficient, is the lack of information about the \emph{spread} of frequencies, once resized. Adding the standard deviation, next to the mean of the frequencies, as inputs for the first layer of learners should fix that; but still, they have not been implemented for a pure matter of time.



\begin{thebibliography}{9}

\bibitem{Biomag2010}
Marcel van Gerven, Ole Jensen,
\emph{Attention modulations of posterior alpha as a control signal for two-dimensional brain-computer interfaces},
Journal of Neuroscience Methods, 2009


\bibitem{Wolpert92}
David H. Wolpert,
\emph{Stacked Generalization},
Neural Networks, 1992

\bibitem{Braindecoding}
E. Olivetti, A. Mognon, S. Greiner and P. Avesani, 
\emph{Brain Decoding: Biases in Error Estimation}, 
Brain Decoding Workshop, 2010

\end{thebibliography}

\end{document}